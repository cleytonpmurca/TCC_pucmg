# -*- coding: utf-8 -*-
"""TCC_0406.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nC8UbbEns0RbR3pY3LQNRHQy-QU0dlRh

## TRABALHO DE CONCLUSÃO DE CURSO
Ciência de dados e Big Data

Cleyton Pereira Murça
"""

#instale o Pycaret, ao final talvez seja necessário reiniciar o ambiente
!pip install pycaret

"""Atenção: após a instalação acima, algumas vezes foi necessário reiniciar o ambiente."""

import numpy as np                                    # Numpy
import pandas as pd                                   # Pandas
from sklearn.model_selection import train_test_split  # Scikit separar treino/teste
import seaborn as sns
from datetime import datetime, timedelta
from scipy import stats
from scipy.stats import spearmanr
import matplotlib.pyplot as plt
import pycaret                                        # Pycaret
from pycaret.regression import *                      # Pycaret para Regressão
from pycaret.utils import enable_colab                # Para executar gráficos no Colab

dados = pd.read_excel("BaseAtendimento0406.xlsx", sheet_name=0)

dados.info()

# ordenar os dados em ordem cronologica
dados.sort_values(by=['dia_atendimento',"Início",'senha'],inplace=True)
#resetar o index
dados.reset_index(drop=True, inplace=True)

dados.head(100)

"""# Duplicados


"""

dados[ dados.duplicated(subset=['senha', 'dia_atendimento', 'atendente'])]

#Exemplo de duplicado
dados[ (dados.senha == 'PFF3') & (dados.dia_atendimento == '2020-03-20')]

"""Uma senha pode conter mais de um serviço e nisso o sistema a registra 2 vezes com o mesmo código da senha e hora_agendada. Mas os serviços são  atendidos em sequencia. Decidi não remover, mas tratar o tempo de espera para esses casos.

# Campos Vazios
"""

#Preenchendo a coluna quantidade de senhas agendadas para as senhas que não tiveram agendamento previamente
df = dados.groupby('dia_atendimento')['qtd_senha_agendada'].first()
for i,row in dados.loc[:].iterrows():
  ind = row['dia_atendimento']
  aux = df[ind]
  dados.loc[i,"qtd_senha_agendada"] = aux

dados.head(100)

"""As senhas de balcão não são agendadas previamente, portanto também não temos dados para a coluna Data Agendada e Hora Agendada. Como hora_agendada será utilizada para criar campo calculado tempo_de_espera,  vamos preenche-la.
//vou considerar inicialmente que a hora agendada é igual a hora que iniciou o serviço.
"""

df = dados.hora_agendada.isnull()
aux = dados[df]['Início']

for i in  aux.index:
  dados.loc[i,'hora_agendada'] = aux[i]

dados.hora_agendada.describe

"""Após calcular o tempo de espera para as senhas de balcão, tenho que corrigir a variável hora_agendada para manter a corretude dos dados.

# Transformando e criando campos

DUracao
"""

len(dados.columns)

dados.insert(11,"duracao",0,allow_duplicates=True) #cria coluna duracao
for i,row in dados[:].iterrows():
    dur = datetime.strptime( row['Fim'].strftime('%H:%M:%S'),'%H:%M:%S')-datetime.strptime( row['Início'].strftime('%H:%M:%S'),'%H:%M:%S')
    dur = dur.total_seconds() / 60
    dados.loc[i,'duracao'] = dur

dados

"""Tempo de espera

preciso levar em consideração as senhas que possuem mais de um serviço. Para o segundo serviço que é executado imediatamente após o primeiro terá o tempo de espera igual a zero. 

 vou preencher o campoo tempo de espera dos registros que tem o campo Data Agendado vazio, baseado na média do tempo de espera
"""

dados.info()

#armazeno o indice dos registros duplicados
dup = dados[ dados.duplicated(subset=['senha', 'dia_atendimento', 'atendente'])].index
dados.insert(12,"tempo_de_espera",0,allow_duplicates=True) #cria coluna duracao
for i,row in dados[:].iterrows():
  if i not in dup:
    dur = datetime.strptime( row['Início'].strftime('%H:%M:%S'),'%H:%M:%S')-datetime.strptime( row['hora_agendada'].strftime('%H:%M:%S'),'%H:%M:%S')
    dur = dur.total_seconds() / 60
    dados.loc[i,'tempo_de_espera'] = dur

"""As variaveis dia_atendimento,Hora_agendada, Inicio, Fim, foram utilizadas para gerar as variaveis Duração e tempo de espera. Serão mantidas para serem utilizadas na geração do campo fila, que indica quantas senhas estao sendo atendidas no momento que ela entrou na fila e outras transformações.

nesse momento serão criadas 2 variaveis :

Fila = Representa os contribuintes que estão esperando pelo serviço, juntamente com os que estão sendo atendidos pelos servidores.

Fila de espera - Somente os contribuintes que estão aguardando pelo serviço.

**Coluna fila**
"""

# ordenar os dados em ordem cronologica
dados.sort_values(by=['dia_atendimento',"hora_agendada",'senha'],inplace=True)
#resetar o index
dados.reset_index(drop=True, inplace=True)

dados.insert(10,"fila",0,allow_duplicates=True) #cria coluna fila
dados.insert(11,"fila_de_espera",0,allow_duplicates=True) #cria coluna fila de espera

#fila armazena a quantidade de senha em atendimento
fila = list()

remover = list()

reg_ant = datetime.strptime("01/01/2000","%d/%m/%Y")

for i,row in dados.loc[:].iterrows():
  if reg_ant < row["dia_atendimento"] :
 #   print("Mudou o dia, limpa a fila")
    fila.clear()
    

  remover.clear()
  for f in fila :
    if dados.loc[f,"Fim"] <= row["hora_agendada"] :
      remover.append(f)

  for r in remover :
    fila.remove(r)     

  #considero na fila quem já está em atendimento
  dados.loc[i,"fila"] = len(fila)   
  #verifico somente quem está aguardando e ainda não está em atendimento
  dados.loc[i,"fila_de_espera"] = len([f for f in fila if dados.loc[f,"Início"]>=row["hora_agendada"]])   
 
  fila.append(i)
  reg_ant =  datetime.strptime( dados.loc[i,"dia_atendimento"].strftime('%d/%m/%Y'),"%d/%m/%Y")

dados.head(30)

"""**Variável qtd atendentes dia**

Como não temos a variável quantidade atendentes atendendo no dia, podemos inferi-la e Cria-la. Entendo que a quantidade de atendentes no dia influencia diretamente no tempo de espera.
"""

#dataframe auxiliar que agrupa quem atendeu no dia
df = dados.groupby('dia_atendimento')['atendente'].unique()
df

dados.insert(9,"qtd_atendentes_dia",0,allow_duplicates=True)
for i,row in dados.loc[:].iterrows():
 ind = row['dia_atendimento']
 aux = df[ind].size
 dados.loc[i,"qtd_atendentes_dia"] = aux

dados.info()

dados_com_outliers = dados.copy()

"""# Tratamento de Inconsistências

Verificando se existe algum erro na base em relação aos horários
"""

dados[ dados.hora_agendada > dados['Início']]

dados[ dados.Fim < dados['Início']]

dados[(dados["duracao"]==0) & (dados["estado"]!="Não compareceu") ].shape

dados[(dados["duracao"]==0) & (dados["estado"]=="Conclusivo") ].shape

"""**Tratamento de inconsistencias**

Registros no estado conclusivo com tempo de atendimento igual a 0 é erro de finalização no sistema o atendente colocou conclusivo. Neste caso o tratamento optado foi alterar o valor do estado de Conclusivo para "Não compareceu". Utilizei uma função Lambda para encontrar os casos e a função loc para setar o valor do campo estado para Não compareceu	.

"""

dados.loc[lambda dados: (dados["duracao"]==0) & (dados["estado"]=='Conclusivo') ]

dados.shape

#mudança
for i,row in dados.loc[lambda dados: (dados["duracao"]==0) & (dados["estado"]=='Conclusivo')].iterrows():
   dados.loc[i,"estado"] = "Não compareceu"

#verificação após mudança
dados.loc[lambda dados: (dados["duracao"]==0) & (dados["estado"]=="Conclusivo")]

"""**tratamento de senhas interrompidas**

Geralemente as senhas interrompidas , quando são reativadas, voltam ao sistema com todos os valores originais das variaveis. Por exemplo, uma senha com hora agendada para as 10h foi interrompida, sendo reativada  as 14h, sua hora agendada continua como 10h, mas o inicio de atendimento será registrado após as 14 quando ela for chamada. Isso dará erro no tempo de espera e irá prejudicar o modelo. 
Assim como estes erros alguns registros fora da normalidade também poderão prejudicar o modelo. Portanto estes deveráo ser excluídos
"""

dados.tempo_de_espera.describe()

dados.info()

sns.displot(dados.tempo_de_espera)

"""Exclusão de Outliers"""

dados.boxplot('tempo_de_espera')

"""Pelo gráfico acima percebe-se muitos outliers, para a exclusão utilizaremos o metodo do z-score. Exclui-se os registros que tem o z-score acima de 3 ou abaixo de -3"""

#calculo do zscore
dados['te_zscore'] = (dados['tempo_de_espera'] - dados['tempo_de_espera'].mean())/dados['tempo_de_espera'].std(ddof=0)

print(dados.shape)
dados.drop(index=dados[dados['te_zscore'] < -3].index.to_list(), inplace=True)
dados.drop(index=dados[dados['te_zscore'] > 3].index.to_list(), inplace=True)
print(dados.shape)
#418 registros foram excluídos

dados.drop(columns='te_zscore',inplace=True)

dados.boxplot('tempo_de_espera')

sns.distplot(dados.tempo_de_espera)

"""Tempo de espera para senha de balcao"""

teste = dados.copy()

#para os registros de senha emitidas no balcão vou preencher o tempo de espera , com a média do dia
df = dados['Data Agendada'].isnull()
aux = dados[df]

for i,row in  aux[:].iterrows():
  dados.loc[i,'tempo_de_espera'] = dados[dados.dia_atendimento==row['dia_atendimento']]['tempo_de_espera'].mean()

sns.distplot(dados.tempo_de_espera)

df = dados['Data Agendada'].isnull()
aux = dados[df]
aux

dados.info()

#para manter a corretude, vamos preencher o campo hora_agenda de acordo com o tempo de espera setado acima
for i,row in  aux[:].iterrows():
  
  ha = (datetime.strptime( row['Início'].strftime('%H:%M:%S'),'%H:%M:%S')-timedelta( minutes=row['tempo_de_espera']))
  #print(ha.strftime('%H:%M:%S'))
  dados.loc[i,'hora_agendada'] = datetime.strptime(ha.strftime('%H:%M:%S'),'%H:%M:%S').time()

dados

"""Fila"""

dados.fila.describe()

dados[dados.dia_atendimento =='2019-02-08'][30:60]
#Data Agendada	hora_agendada	qtd_senha_agendada	dia_atendimento	qtd_senha_atendida	atendente	senha	Início	Fim	qtd_atendentes_dia	estado	fila	fila_de_espera	Serviço	duracao	tempo_de_espera

dados[dados.fila > 10]

"""Ao verificar visualmente identificou-se que a distorção na quantidade de senhas na fila acontece em serviços chamados pelo atendente 0. Neste caso me lembro que o atendente 0 não fazia o mesmo serviço que os demais, somente recebia protocolos para serem executados por outros servidores. Assim decidi excluir o atendente 0 e recalcular a coluna fila."""

print(dados.shape)
dados.drop(index= dados[ dados.atendente == 0].index.to_list(),inplace=True)
print(dados.shape)

dados.fila.unique()

#fila armazena a quantidade de senha em atendimento
fila = list()

remover = list()

reg_ant = datetime.strptime("01/01/2000","%d/%m/%Y")

for i,row in dados.loc[:].iterrows():
  if reg_ant < row["dia_atendimento"] :
 #   print("Mudou o dia, limpa a fila")
    fila.clear()
    

  remover.clear()
  for f in fila :
    
    if  dados.loc[f,"Fim"] <= row.hora_agendada:
      remover.append(f)

  for r in remover :
    fila.remove(r)     

  #considero na fila quem já está em atendimento e aguardando
  dados.loc[i,"fila"] = len(fila)   
  #verifico somente quem está aguardando e ainda não está em atendimento
  dados.loc[i,"fila_de_espera"] = len([f for f in fila if dados.loc[f,"Início"]>=row["hora_agendada"]])   
 
  fila.append(i)
  reg_ant =  datetime.strptime( dados.loc[i,"dia_atendimento"].strftime('%d/%m/%Y'),"%d/%m/%Y")

dados.fila.unique()

dados.fila_de_espera.unique()

dados.fila.describe()

"""# Tratando categoricas"""

dados.senha = dados.senha.str[:3]

dados.info()

encod_senha = dados.groupby('senha')['tempo_de_espera'].mean().round(2)
print(encod_senha)

dados.groupby('senha').count()

dados['senha'] = dados['senha'].map(encod_senha)

sns.displot(dados['estado'])

dados['estado'].value_counts()

top = dados['estado'].isin(dados['estado'].value_counts().index[:2])
dados.loc[~top, 'estado'] = "other"

sns.displot(dados['estado'])

dados_sem_outliers = dados.copy()

"""# Criando colunas a partir de registros passados

Nossa variavel alvo (Tempo_de_espera) é depende da quantidade de atendentes no dia, quantidade de senhas agendada  e das outras características referentes às senhas que estão sendo atendidas. Ou seja, o tempo de espera vai variar  dependendo do registro anterior da senha que está sendo atendida( tipo de senha, duração, se foi conclusiva etc.)
Por isso vou fazer uma junção no dataframe para que meu registro referente a senha que está no momento de ser atendida, tenha colunas referentes às senhas que estão sendo atendidas e que determinarão o tempo de espera daquela senha.
"""

dados.reset_index(drop=True, inplace=True)

dados.info()

#retirando colunas e deixando somente as que serão replicadas com os valores das senhas que estão na fila de atendimento
df = dados.drop(columns={"qtd_atendentes_dia","qtd_senha_agendada",'qtd_senha_atendida','Início','estado','Serviço'})

df.info()

df.columns = ["Data Agendada_t1","hora_agendada_t1",'dia_atendimento_t1',"atendente_t1",'senha_t1',"Fim_t1","fila_t1",'fila_de_espera_t1','duracao_t1','tempo_de_espera_t1']
df.head()

df.info()

"""execução demora ~10min"""

#Definições de variaveis auxiliares
novo = pd.DataFrame()
left = pd.DataFrame() #recebe as senhas que estão na fila ou em execução
right = pd.DataFrame() #recebe a nova senha que entrou na fila
fila = list() #faz o controle de qual senha está na fila
remover = list() 
match = 0 #indica se encontrou na fila a senha que antecedeu a nova senha


reg_ant = datetime.strptime("01/01/2000","%d/%m/%Y")  
for i,row in dados.loc[:].iterrows():
 
  if reg_ant < row["dia_atendimento"] :
    fila.clear()
  
  remover.clear()  
  
  for f in fila :
    if (dados.loc[f,'atendente']==row['atendente']):
      match = f
    if df.loc[f,'Fim_t1'] <= row["hora_agendada"] :
      remover.append(f)
      
  if match == 0:
    for f in fila :
      if f not in remover:
         left = pd.concat([left,dados.loc[[f]]])
         right = pd.concat([right, df.loc[[i]] ])
         break;   
  else:
    left = pd.concat([left, dados.loc[[match]] ])
    right = pd.concat([right, df.loc[[i]] ])

  for r in remover :
    fila.remove(r) 

  fila.append(i)
  reg_ant =  datetime.strptime( dados.loc[i,"dia_atendimento"].strftime('%d/%m/%Y'),"%d/%m/%Y")
  match = 0

left.shape

right.shape

left.reset_index(drop=True, inplace=True)
right.reset_index(drop=True, inplace=True)
novo = pd.concat([left,right],axis=1)
novo

novo.insert(10,"tempo_em_execucao",0,allow_duplicates=True)

for i,row in novo[:].iterrows():
  if ((row['Fim']>row['hora_agendada_t1']) & (row['Início'] <= row['hora_agendada_t1'])):
    dur = datetime.strptime( row['hora_agendada_t1'].strftime('%H:%M:%S'),'%H:%M:%S')-datetime.strptime( row['Início'].strftime('%H:%M:%S'),'%H:%M:%S')
    dur = dur.total_seconds() / 60
    novo.loc[i,'tempo_em_execucao'] = dur

novo.tempo_em_execucao.unique()

novo.info()

novo.drop(columns={'Data Agendada','dia_atendimento','hora_agendada','Início','Serviço','Fim','Data Agendada_t1','dia_atendimento_t1','hora_agendada_t1','Fim_t1'},axis=1,inplace=True)

novo.info()

dados = novo

"""Deixei somente variaveis que numa possível implementação estarão disponíveis. Por exemplo não tenho a duração de uma senha que acabou de entrar na fila, mas tenho que prever o tempo de espera. Assim não criei a variavel duração(t+1)

# Explorando
"""

dados.info()

dados.isnull().sum()

dados.describe()

sns.displot(dados['senha'])
sns.displot(dados['senha_t1'])
sns.displot(dados['qtd_senha_agendada'])
sns.displot(dados['qtd_senha_atendida'])
sns.displot(dados['atendente'])
sns.displot(dados['atendente_t1'])
sns.displot(dados['duracao'])
sns.displot(dados['duracao_t1'])
sns.displot(dados['fila'])
sns.displot(dados['fila_t1'])
sns.displot(dados['qtd_atendentes_dia'])
sns.displot(dados['fila_de_espera'])
sns.displot(dados['fila_de_espera_t1'])
sns.displot(dados['tempo_de_espera'])
sns.displot(dados['tempo_de_espera_t1'])
sns.displot(dados['tempo_em_execucao'])
sns.displot(dados['estado'])

dados.duracao.value_counts()

dados.estado.value_counts()

dados.groupby('fila_de_espera_t1')['tempo_de_espera_t1'].count()

dados.groupby('fila_de_espera_t1')['tempo_de_espera_t1'].mean()

dados.groupby('qtd_atendentes_dia')['tempo_de_espera_t1'].mean()

sns.scatterplot(dados.tempo_de_espera_t1,dados.qtd_atendentes_dia)

sns.distplot(np.log1p(dados['tempo_de_espera']))

#sns.pairplot(dados)

corrmat = dados.corr()
plt.figure(figsize=(20,10))
k = 15 #qtd de variaveis para o heatmap
cols = corrmat.nlargest(k, 'tempo_de_espera_t1')['tempo_de_espera_t1'].index
cm = np.corrcoef(dados[cols].values.T)
sns.set(font_scale=1.25)
hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)
plt.show()

dados.info()

from scipy import stats
from scipy.stats import spearmanr
data1=dados.filter(items={'senha','senha_t1','duracao','duracao_t1','qtd_senha_agendada','qtd_atendentes_dia','qtd_senha_atendida','tempo_em_execucao'})
data2 = dados['tempo_de_espera_t1']

for row in data1.columns:
  print(row)
  coef, p = spearmanr(data1[row], data2)
  print('Coeficiente de correlação Spearmans : %.3f' % coef)
#print(coef)
#print(p)
  # utilizando uma confiança de 5%
  alpha = 0.05
  if p > alpha:
  	print('### SEM CORRELAÇÃO (não rejeita H0) p=%.3f' % p)
  else:
  	print('Correlacionados (reject H0) p=%.3f' % p)
  print('**************')

"""Correlação dos dados categoricos"""

data1 = dados.filter(items=['senha','estado','atendente','fila','fila_de_espera','fila_t1','fila_de_espera_t1','tempo_de_espera_t1'])

corr = data1.corr(method='kendall')
corr

from scipy.stats import kendalltau
#data1 = dados.filter(items=['senha','atendente','estado_cod','atendente(t+1)','estado_cod(t+1)','senha(t+1)'])

data2 = dados['tempo_de_espera_t1']

for row in data1.columns:
  print(row)
  coef, p = kendalltau(data1[row], data2)
  print('coeficiente de correlação Kendall: %.3f' % coef)
  # confiança
  alpha = 0.05
  if p > alpha:
	  print('**NÃO CORRELACIONADOS** p=%.3f' % p)
  else:
	  print('correlacionados p=%.3f' % p)
  print("*******************")

"""# target Encoding - Variavel Senha"""

n_senha1 = novo.groupby('senha_t1')['tempo_de_espera_t1'].mean()
novo['senha_t1'] = novo['senha_t1'].map(n_senha1)

sns.displot(novo['senha'])

n_senha1 = novo.groupby('senha')['tempo_de_espera_t1'].mean()
novo['senha'] = novo['senha'].map(n_senha1)

"""# CRIANDO O MODELO - Dados sem tratamento

**Utilizando o Pycaret para comparar qual o melhor algoritmo e criar o modelo**
"""

dados_com_outliers.info()

df = dados_com_outliers.drop(columns={'Data Agendada','dia_atendimento','hora_agendada','Início','Fim', 'Serviço'})

df.info()

df

df.senha = df.senha.str[:3]

df.info()

"""Separando uma parte dos dados para avaliar o modelo implementado. Assim teremos uma base para modelar e dados não vistos para avaliar."""

data = df.sample(frac=0.9, random_state=786)
data_unseen = df.drop(data.index)

data.reset_index(drop=True, inplace=True)
data_unseen.reset_index(drop=True, inplace=True)

print('Dados para o Modelo: ' + str(data.shape))
print('Dados não vistos para predição: ' + str(data_unseen.shape))

train, test = train_test_split( data, test_size=0.3, 
                                     random_state=42)

print(len(train))
print(len(test))

train.describe()

train.info()

"""Após dividir a base de treino e teste, vamos normalizar todos os campos"""

reg = setup(data = train,           # Banco de dados
              target = 'tempo_de_espera',   # o que estamos tentando prever
              train_size = 0.7  
      )     # Proporção do banco de treino

compare_models( round = 4,  sort = 'mae')

model_tcc = create_model('rf')

plot_model(model_tcc,plot='error')

plot_model(model_tcc, plot='residuals')

plot_model(model_tcc, 'feature')

predict_model(model_tcc, data=test)

res = predict_model(model_tcc, data=test)

sns.scatterplot(res['tempo_de_espera'],res['Label'])



final_model = finalize_model(model_tcc)

predict_model(final_model);

aux = predict_model(final_model, data=data_unseen)

aux

aux.reset_index(drop=True, inplace=True)
aux1 = aux.head(200)
plt.clf()
fig = plt.figure(figsize=(20,10))
fig.suptitle('Previsão x Real ')
predicted, = plt.plot(aux1.index, aux1['Label'], 'go-', label='Previsto')
actual, = plt.plot(aux1.index, aux1['tempo_de_espera'], 'ro-', label='Real')
plt.legend(handles=[predicted, actual])
plt.show()

#aux = predict_model(final_model, data=aval)

from sklearn.metrics import mean_absolute_error, mean_squared_error
from math import sqrt
print("MAE test score:", mean_absolute_error( aux['tempo_de_espera'], aux['Label']))
print("RMSE test score:", sqrt(mean_squared_error( aux['tempo_de_espera'], aux['Label'])))

"""# CRIANDO O MODELO - Dados Tratados

**Utilizando o Pycaret para comparar qual o melhor algoritmo e criar o modelo**
"""

dados_sem_outliers.info()

df = dados_sem_outliers.drop(columns={'Data Agendada','dia_atendimento','hora_agendada','Início','Fim','Serviço'})

df

df.info()

data = df.sample(frac=0.9, random_state=786)
data_unseen = df.drop(data.index)

data.reset_index(drop=True, inplace=True)
data_unseen.reset_index(drop=True, inplace=True)

print('Dados para o Modelo: ' + str(data.shape))
print('Dados não vistos para predição: ' + str(data_unseen.shape))

train, test = train_test_split( data, test_size=0.3, 
                                     random_state=42)

train.describe()

from sklearn import preprocessing 
  
min_max_scaler = preprocessing.MinMaxScaler(feature_range =(0, 1)) 
num_cols = ['qtd_senha_agendada','qtd_senha_atendida','duracao', 'senha']

# aplico standardization em variaveis numericas
for i in num_cols:
  train[i] = min_max_scaler.fit_transform(train[[i]]) 
  test[i] = min_max_scaler.fit_transform(test[[i]])
  data_unseen[i] = min_max_scaler.fit_transform(data_unseen[[i]])

"""Após dividir a base de treino e teste, vamos normalizar todos os campos"""

reg = setup(data = train,           # Banco de dados
              target = 'tempo_de_espera',   # o que estamos tentando prever
              train_size = 0.7           
            
      )     # Proporção do banco de treino

compare_models( round = 4,  sort = 'mae')

model_tcc = create_model('lightgbm')

plot_model(model_tcc,plot='error')

plot_model(model_tcc, plot='residuals')

plot_model(model_tcc, 'feature')

predict_model(model_tcc, data=test)

res = predict_model(model_tcc, data=test)

res[res['tempo_de_espera']==0]

final_model = finalize_model(model_tcc)

predict_model(final_model);

sns.scatterplot(res['tempo_de_espera'],res['Label'])

#unseen_predictions
aux = predict_model(final_model, data=data_unseen)

aux1 = aux.copy()

aux.reset_index(drop=True, inplace=True)
aux = aux.head(200)
plt.clf()
fig = plt.figure(figsize=(20,10))
fig.suptitle('Previsão x Real ')
predicted, = plt.plot(aux.index, aux['Label'], 'go-', label='Previsto')
actual, = plt.plot(aux.index, aux['tempo_de_espera'], 'ro-', label='Real')
plt.legend(handles=[predicted, actual])
plt.show()

from sklearn.metrics import mean_absolute_error, mean_squared_error
from math import sqrt
print("MAE test score:", mean_absolute_error( aux1['tempo_de_espera'], aux1['Label']))
print("RMSE test score:", sqrt(mean_squared_error( aux1['tempo_de_espera'], aux1['Label'])))

"""# CRIANDO O MODELO - Dados Tratados e campos extras

**Utilizando o Pycaret para comparar qual o melhor algoritmo e criar o modelo**
"""

novo.info()

df = novo

df

df.info()

data = df.sample(frac=0.9, random_state=786)
data_unseen = df.drop(data.index)

data.reset_index(drop=True, inplace=True)
data_unseen.reset_index(drop=True, inplace=True)

print('Dados para o Modelo: ' + str(data.shape))
print('Dados não vistos para predição: ' + str(data_unseen.shape))

train, test = train_test_split( data, test_size=0.3, 
                                     random_state=42)

train.describe()

from sklearn import preprocessing 
  
min_max_scaler = preprocessing.MinMaxScaler(feature_range =(0, 1)) 
num_cols = ['qtd_senha_agendada','qtd_senha_atendida','duracao', 'senha']

# aplico standardization em variaveis numericas
for i in num_cols:
  train[i] = min_max_scaler.fit_transform(train[[i]]) 
  test[i] = min_max_scaler.fit_transform(test[[i]])
  data_unseen[i] = min_max_scaler.fit_transform(data_unseen[[i]])

reg = setup(data = train,           # Banco de dados
              target = 'tempo_de_espera_t1',   # o que estamos tentando prever
              train_size = 0.7 ,
          ignore_features=['duracao_t1']        
      )     # Proporção do banco de treino

compare_models( round = 4,  sort = 'mae')

model_tcc = create_model('lightgbm')

plot_model(model_tcc,plot='error')

plot_model(model_tcc, plot='residuals')

plot_model(model_tcc, 'feature')

predict_model(model_tcc, data=test)

res = predict_model(model_tcc, data=test)

print("MAE test score:", mean_absolute_error( res['tempo_de_espera_t1'], res['Label']))
print("RMSE test score:", sqrt(mean_squared_error( res['tempo_de_espera_t1'], res['Label'])))

res[res['tempo_de_espera_t1']==0]

final_model = finalize_model(model_tcc)

predict_model(final_model);

#unseen_predictions
aux = predict_model(final_model, data=data_unseen)

#aux = predict_model(final_model, data=test)
aux1 = aux.copy()

aux.reset_index(drop=True, inplace=True)
aux = aux.head(200)
plt.clf()
fig = plt.figure(figsize=(20,10))
fig.suptitle('Previsão x Real ')
predicted, = plt.plot(aux.index, aux['Label'], 'go-', label='Previsto')
actual, = plt.plot(aux.index, aux['tempo_de_espera_t1'], 'ro-', label='Real')
plt.legend(handles=[predicted, actual])
plt.show()

from sklearn.metrics import mean_absolute_error, mean_squared_error
from math import sqrt
print("MAE test score:", mean_absolute_error( aux1['tempo_de_espera_t1'], aux1['Label']))
print("RMSE test score:", sqrt(mean_squared_error( aux1['tempo_de_espera_t1'], aux1['Label'])))

"""# GLM"""

df = novo

df.info()

dummy = pd.get_dummies(df['estado']) 
df = pd.concat([df,dummy],axis=1)

df.drop(columns='estado',axis=1,inplace=True)

df = df.rename (columns={'Não compareceu':'n_compareceu'})

data = df.sample(frac=0.9, random_state=786)
data_unseen = df.drop(data.index)

data.reset_index(drop=True, inplace=True)
data_unseen.reset_index(drop=True, inplace=True)

print('Dados para o Modelo: ' + str(data.shape))
print('Dados não vistos para predição: ' + str(data_unseen.shape))

data.columns

import pandas as pd
from patsy import dmatrices
import numpy as np
import statsmodels.api as sm
import matplotlib.pyplot as plt



#divide em conjuntos de treino e teste
mask = np.random.rand(len(data)) < 0.7
df_train = data[mask]
df_test = data[~mask]
print('Training data set length='+str(len(df_train)))
print('Testing data set length='+str(len(df_test)))

#Setup da expressão de regression em patsy notation. Aqui diz que a variavel tempo_de_espera_t1 é nossa variavel dependente
expr = 'tempo_de_espera_t1 ~ qtd_senha_agendada+ qtd_senha_atendida+ atendente+ senha+ qtd_atendentes_dia+ tempo_em_execucao+ fila+ fila_de_espera+ duracao+ tempo_de_espera+ atendente_t1+ senha_t1+ fila_t1+ fila_de_espera_t1+ Conclusivo+ n_compareceu+ other'

#configura as matrizes
y_train, X_train = dmatrices(expr, df_train, return_type='dataframe')
y_test, X_test = dmatrices(expr, df_test, return_type='dataframe')

#Usando o statsmodels GLM class, treina o modelo de regressão Poisson no conjunto de treino.
poisson_training_results = sm.GLM(y_train, X_train, family=sm.families.Poisson()).fit()

print(poisson_training_results.summary())

#Fazendo predições no conjunto de teste.
poisson_predictions = poisson_training_results.get_prediction(X_test)

predictions_summary_frame = poisson_predictions.summary_frame()
print(predictions_summary_frame)

predicted_counts=predictions_summary_frame['mean']
actual_counts = y_test['tempo_de_espera_t1']

#plota o grafico
fig = plt.figure()
fig.suptitle('Predicted versus actual ')
predicted, = plt.plot(X_test.index, predicted_counts, 'go-', label='Predicted counts')
actual, = plt.plot(X_test.index, actual_counts, 'ro-', label='Actual counts')
plt.legend(handles=[predicted, actual])
plt.show()

plt.clf()
fig = plt.figure()
fig.suptitle('Scatter plot of Actual versus Predicted counts')
plt.scatter(x=predicted_counts, y=actual_counts, marker='.')
plt.xlabel('Predicted counts')
plt.ylabel('Actual counts')
plt.show()

#plt.figure(figsize=(20,10))
plt.clf()
fig = plt.figure(figsize=(20,10))
fig.suptitle('Previsto versus Real ')
predicted, = plt.plot(X_test.head(200).index, predicted_counts.head(200), 'go-', label='Previsto')
actual, = plt.plot(X_test.head(200).index, actual_counts.head(200), 'ro-', label='Real')
plt.legend(handles=[predicted, actual])
plt.show()

from sklearn.metrics import mean_absolute_error, mean_squared_error
from math import sqrt
print("MAE test score:", mean_absolute_error(actual_counts, predicted_counts))
print("RMSE test score:", sqrt(mean_squared_error(actual_counts, predicted_counts)))

y_aval, X_aval = dmatrices(expr, data_unseen, return_type='dataframe')

poisson_predictions_aval = poisson_training_results.get_prediction(X_aval)
predictions_summary_frame = poisson_predictions_aval.summary_frame()
predicted_counts=predictions_summary_frame['mean']
actual_counts = y_aval['tempo_de_espera_t1']
print("MAE test score:", mean_absolute_error(actual_counts, predicted_counts))
print("RMSE test score:", sqrt(mean_squared_error(actual_counts, predicted_counts)))